{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_NWHiQb8mCK"
   },
   "outputs": [],
   "source": [
    "%pwd # print woriking directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wywMZxfJ8mEf"
   },
   "outputs": [],
   "source": [
    "# yolo를 사용하는데 필요한 라이브러리 설치하기\n",
    "%cd yolov5/\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-srIPOQe8mLS"
   },
   "outputs": [],
   "source": [
    "exp_path = \"C:/Users/AI/Auto_Farming/yolov5/runs/detect/exp/\"\n",
    "path = 'C:/Users/AI/Auto_Farming/yolov5/'\n",
    "weight = 'C:/Users/AI/Auto_Farming/yolov5/runs/train/insam_yolov5s_results/weights/best.pt'\n",
    "source = 'C:/Users\\AI/Auto_Farming/image/capture.png' \n",
    "try:\n",
    "    os.unlink(exp_path+\"labels/capture.txt\")\n",
    "except:\n",
    "    with open(\"C:/Users/AI/Auto_Farming/yolov5/runs/detect/exp/labels/capture.txt\", 'w') as f:\n",
    "        f.write('')\n",
    "rs = !python {path}detect3.py --weight {weight} --source {source} --save-txt --exist-ok --hide-conf --hide-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = !python {path}detect6.py --weight {weight} --source 0 --save-txt --exist-ok --hide-conf --hide-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect6: \u001b[0mweights=['C:/Users/AI/Auto_Farming/yolov5/runs/train/insam_yolov5s_results/weights/best.pt'], source=0, data=yolov5\\data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5\\runs\\detect, name=exp, exist_ok=True, line_thickness=3, hide_labels=True, hide_conf=True, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  v6.2-219-ga83d2a5 Python-3.9.12 torch-1.12.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "1/1: 0...  Success (inf frames 640x480 at 30.00 FPS)\n",
      "\n",
      "정상 검출 갯수 : 0\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 0\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 0\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 0\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 0\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 0\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 0\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 0\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 0\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 1\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 2\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 3\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 4\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 5\n",
      "피더 작동\n",
      "그리퍼 각도 : 0\n",
      "ERROR\n",
      "정상 검출 갯수 : 6\n",
      "피더 작동 안함\n",
      "그리퍼 각도 : 225\n",
      "좌표 : 285, 87\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AI\\Auto_Farming\\yolov5\\detect6.py\", line 339, in <module>\n",
      "    main(opt)\n",
      "  File \"C:\\Users\\AI\\Auto_Farming\\yolov5\\detect6.py\", line 329, in main\n",
      "    run(**vars(opt))\n",
      "  File \"C:\\Users\\AI\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\AI\\Auto_Farming\\yolov5\\detect6.py\", line 265, in run\n",
      "    if vid_path[i] != save_path:  # new video\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "for i in rs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7ld0abl8mNe"
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "exp_path = \"C:/Users/AI/Auto_Farming/yolov5/runs/detect/exp/\"\n",
    "path = 'C:/Users/AI/Auto_Farming/yolov5/'\n",
    "weight = 'C:/Users/AI/Auto_Farming/yolov5/runs/train/insam_yolov5s_results/weights/best.pt'\n",
    "source = 'C:/Users\\AI/Auto_Farming/image/capture.png' \n",
    "save_img = 'C:/Users\\AI/Auto_Farming/image/capture.png'\n",
    "coordinate_path = \"C:/Users/AI/Auto_Farming/yolov5/runs/detect/exp/labels/\"\n",
    "frame_img_path = \"C:/Users/AI/Auto_Farming/image/capture.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "webcam = cv2.VideoCapture(0)\n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "while webcam.isOpened():\n",
    "    status, frame = webcam.read()\n",
    "    if status:\n",
    "        cv2.imshow(\"test\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def th_camera(event):   # thread 함수\n",
    "#     webcam = cv2.VideoCapture(1)\n",
    "#     if not webcam.isOpened():\n",
    "#         print(\"Could not open webcam\")\n",
    "#         exit()\n",
    "#     while webcam.isOpened():\n",
    "#         status, frame = webcam.read()\n",
    "#         if status:\n",
    "#             cv2.imshow(\"test\", frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "#     webcam.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315도\n",
      "뇌두 좌표 : [ 30 263]\n"
     ]
    }
   ],
   "source": [
    "# from threading import Event\n",
    "# event=Event()\n",
    "# th = threading.Thread(target=th_camera, args=(event, )) # def된 함수를 thread 생성\n",
    "# th.setDaemon(True) # main 함수와 같이 시작하고 끝나도록 daemon 함수로 설정 (병렬동작이 가능하도록 하는 기능)\n",
    "# th.start() # thread 동작\n",
    "    \n",
    "cap = cv2.VideoCapture(0)\n",
    "while True :\n",
    "    try:\n",
    "        os.unlink(exp_path+\"labels/capture.txt\")\n",
    "    except:\n",
    "        print(\"labels.txt 없음\")\n",
    "        \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break \n",
    "    key = cv2.waitKey(330)\n",
    "    resize_frame = frame[:,:480]\n",
    "    cv2.imwrite(save_img, resize_frame,\n",
    "               params=[cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "    rs=!python {path}detect3.py --weight {weight} --img 480 --source {source} --save-txt --exist-ok --hide-conf --hide-labels\n",
    "    \n",
    "    with open(coordinate_path+\"capture.txt\", \"r\") as f:\n",
    "        txt = f.readlines()  \n",
    "\n",
    "    gc, hc, ga, da, min_gl = [], [], [], [], 640\n",
    "    [gc.append(i) if i[0] == '0' else hc.append(i) for i in txt]\n",
    "\n",
    "    gn, hn, p = len(gc), len(hc), 0\n",
    "\n",
    "    for i in range(gn):\n",
    "        g = gc[i][2:-1].split(' ')\n",
    "        gltx, glty, grbx, grby = int(g[0]), int(g[1]), int(g[2]), int(g[3])\n",
    "        lt, rt, lb, rb = [gltx, glty], [grbx, glty], [gltx, grby], [grbx, grby]\n",
    "        globals()[\"g{}\".format(i)] = [lt, rt, lb, rb]\n",
    "\n",
    "        for j in range(hn):\n",
    "            h = hc[j][2:-1].split(' ')\n",
    "            hltx, hlty, hrbx, hrby = int(h[0]), int(h[1]), int(h[2]), int(h[3])\n",
    "            globals()[\"h{}\".format(j)] = [int((hltx+hrbx)/2), int((hlty+hrby)/2)]\n",
    "            if (globals()[f\"g{i}\"][3][0] > globals()[f\"h{j}\"][0] > globals()[f\"g{i}\"][0][0])\\\n",
    "            and (globals()[f\"g{i}\"][3][1] > globals()[f\"h{j}\"][1] > globals()[f\"g{i}\"][0][1]):\n",
    "                globals()[\"g{}\".format(i)].append(globals()[\"h{}\".format(j)])\n",
    "\n",
    "        ga.append(globals()[\"g{}\".format(i)])\n",
    "\n",
    "    for i in ga:\n",
    "        if len(i) == 5:\n",
    "            da.append(i)\n",
    "\n",
    "    # da=(1,2,3,4) # 개체수 없는 시나리오\n",
    "\n",
    "    if len(da) <= 5:\n",
    "        p = 1\n",
    "        print('피더 작동')\n",
    "\n",
    "    else: \n",
    "        for v in da:\n",
    "            if min_gl > v[0][0]:\n",
    "                    min_gl = v[0][0] \n",
    "\n",
    "        min_gl = g1[0][0] # 가장 가까운게 뇌두가 없어서 임시로 값 지정해둔거        \n",
    "\n",
    "        for i,value in enumerate(da):\n",
    "            if min_gl == value[0][0]:\n",
    "                globals()[\"g{}\".format(i)] = np.array(globals()[\"g{}\".format(i)])\n",
    "                best = globals()[\"g{}\".format(i)]\n",
    "                alt = abs(globals()[\"g{}\".format(i)][0]-globals()[\"g{}\".format(i)][-1])\n",
    "                art = abs(globals()[\"g{}\".format(i)][1]-globals()[\"g{}\".format(i)][-1])\n",
    "                alb = abs(globals()[\"g{}\".format(i)][2]-globals()[\"g{}\".format(i)][-1])\n",
    "                arb = abs(globals()[\"g{}\".format(i)][3]-globals()[\"g{}\".format(i)][-1])\n",
    "                altu, artu = int(math.sqrt((alt[0]**2)+(alt[1]**2))), int(math.sqrt((art[0]**2)+(art[1]**2)))\n",
    "                albu, arbu = int(math.sqrt((alb[0]**2)+(alb[1]**2))), int(math.sqrt((arb[0]**2)+(arb[1]**2)))\n",
    "                bgc = {'LT':altu, 'RT':artu, 'LB':albu, 'RB':arbu}\n",
    "                bgc_sorted=sorted(bgc.items(), key=lambda x:x[1])\n",
    "                if bgc_sorted[1][1] - bgc_sorted[0][1] < 13:\n",
    "                    if bgc_sorted[0][0] == 'RT' and bgc_sorted[1][0] == 'RB':\n",
    "                        print(\"0도\")\n",
    "                    elif bgc_sorted[1][0] == 'RT' and bgc_sorted[0][0] == 'RB':\n",
    "                        print(\"0도\")\n",
    "                    elif bgc_sorted[0][0] == 'LT'and bgc_sorted[1][0] == 'RT': \n",
    "                        print(\"90도\")\n",
    "                    elif bgc_sorted[1][0] == 'LT'and bgc_sorted[0][0] == 'RT':\n",
    "                        print(\"90도\")\n",
    "                    elif bgc_sorted[0][0] == 'LT' and bgc_sorted[1][0] == 'LB':\n",
    "                        print(\"180도\")\n",
    "                    elif bgc_sorted[1][0] == 'LT' and bgc_sorted[0][0] == 'LB':\n",
    "                        print(\"180도\")\n",
    "                    elif bgc_sorted[0][0] == 'LB' and bgc_sorted[1][0] == 'RB': \n",
    "                        print(\"270도\")\n",
    "                    elif bgc_sorted[1][0] == 'LB' and bgc_sorted[0][0] == 'RB':\n",
    "                        print(\"270도\")\n",
    "                else:\n",
    "                    if bgc_sorted[0][0] == 'RT':\n",
    "                        print(\"45도\")\n",
    "                    elif bgc_sorted[0][0] == 'LT':\n",
    "                        print(\"135도\")\n",
    "                    elif bgc_sorted[0][0] == 'LB': \n",
    "                        print(\"225도\")\n",
    "                    elif bgc_sorted[0][0] == 'RB':\n",
    "                        print(\"315도\")\n",
    "                print(f'뇌두 좌표 : {globals()[\"g{}\".format(i)][-1]}')\n",
    "        try:\n",
    "            frame_img = cv2.imread(frame_img_path, cv2.IMREAD_COLOR)\n",
    "#             frame_img = cv2.cvtColor(frame_img, cv2.COLOR_BGR2RGB)\n",
    "            frame_img = cv2.rectangle(frame_img, (best[0][0], best[0][1]), (best[3][0], best[3][1]),(0,255,0), 3)\n",
    "            frame_img = cv2.circle(frame_img, (best[-1][0],best[-1][1]),5,(255,0,0), -1)\n",
    "            \n",
    "            cv2.imshow(\"test\", frame_img)\n",
    "        except:\n",
    "            print(\"best 없음\")\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " rs=!python {path}detect3.py --weight {weight} --img 480 --source {source} --save-txt --exist-ok --hide-conf --hide-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect3: \u001b[0mweights=['C:/Users/AI/Auto_Farming/yolov5/runs/train/insam_yolov5s_results/weights/best.pt'], source=C:/Users\\AI/Auto_Farming/image/capture.png, data=yolov5\\data\\coco128.yaml, imgsz=[480, 480], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5\\runs\\detect, name=exp, exist_ok=True, line_thickness=3, hide_labels=True, hide_conf=True, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  v6.2-219-ga83d2a5 Python-3.9.12 torch-1.12.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/1 C:\\Users\\AI\\Auto_Farming\\image\\capture.png: 480x480 9 Ginsengs, 10 heads, 114.7ms\n",
      "Speed: 0.0ms pre-process, 114.7ms inference, 2.0ms NMS per image at shape (1, 3, 480, 480)\n",
      "Results saved to \u001b[1myolov5\\runs\\detect\\exp\u001b[0m\n",
      "1 labels saved to yolov5\\runs\\detect\\exp\\labels\n"
     ]
    }
   ],
   "source": [
    "for i in rs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 색상 검출 하는 방향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "exp_path = \"C:/Users/AI/Auto_Farming/yolov5/runs/detect/exp/\"\n",
    "path = 'C:/Users/AI/Auto_Farming/yolov5/'\n",
    "weight = 'C:/Users/AI/Auto_Farming/yolov5/runs/train/insam_yolov5s_results/weights/best.pt'\n",
    "source = 'C:/Users\\AI/Auto_Farming/image/masked.png' \n",
    "save_img = 'C:/Users\\AI/Auto_Farming/image/capture.png'\n",
    "save_img2 = 'C:/Users\\AI/Auto_Farming/image/masked.png'\n",
    "coordinate_path = \"C:/Users/AI/Auto_Farming/yolov5/runs/detect/exp/labels/\"\n",
    "frame_img_path = \"C:/Users/AI/Auto_Farming/image/capture.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m frame_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(frame_img_path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m    104\u001b[0m frame_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame_img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m--> 105\u001b[0m frame_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrectangle(frame_img, (\u001b[43mbest\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], best[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]), (best[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m0\u001b[39m], best[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m1\u001b[39m]),(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    106\u001b[0m frame_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcircle(frame_img, (best[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m],best[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]),\u001b[38;5;241m5\u001b[39m,(\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    107\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame_img)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best' is not defined"
     ]
    }
   ],
   "source": [
    "# 색상 검출 활용본\n",
    "lower = np.array([5, 30, 50])\n",
    "higher = np.array([35, 255, 255])\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True :\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break \n",
    "    key = cv2.waitKey(330)\n",
    "    resize_frame = frame[:,:480]\n",
    "    cv2.imwrite(save_img, resize_frame,\n",
    "               params=[cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "    img = cv2.imread(save_img, cv2.IMREAD_COLOR)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(img_hsv, lower, higher)\n",
    "    masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    cv2.imshow(\"test\", masked_img)\n",
    "    cv2.imwrite(save_img2, resize_frame,\n",
    "           params=[cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "    rs=!python {path}detect3.py --weight {weight} --img 480 --source {source} --save-txt --exist-ok --hide-conf --hide-labels\n",
    "    \n",
    "    with open(coordinate_path+\"masked.txt\", \"r\") as f:\n",
    "        txt = f.readlines()  \n",
    "\n",
    "    gc, hc, ga, da, min_gl = [], [], [], [], 640\n",
    "    [gc.append(i) if i[0] == '0' else hc.append(i) for i in txt]\n",
    "\n",
    "    gn, hn, p = len(gc), len(hc), 0\n",
    "\n",
    "    for i in range(gn):\n",
    "        g = gc[i][2:-1].split(' ')\n",
    "        gltx, glty, grbx, grby = int(g[0]), int(g[1]), int(g[2]), int(g[3])\n",
    "        lt, rt, lb, rb = [gltx, glty], [grbx, glty], [gltx, grby], [grbx, grby]\n",
    "        globals()[\"g{}\".format(i)] = [lt, rt, lb, rb]\n",
    "\n",
    "        for j in range(hn):\n",
    "            h = hc[j][2:-1].split(' ')\n",
    "            hltx, hlty, hrbx, hrby = int(h[0]), int(h[1]), int(h[2]), int(h[3])\n",
    "            globals()[\"h{}\".format(j)] = [int((hltx+hrbx)/2), int((hlty+hrby)/2)]\n",
    "            if (globals()[f\"g{i}\"][3][0] > globals()[f\"h{j}\"][0] > globals()[f\"g{i}\"][0][0])\\\n",
    "            and (globals()[f\"g{i}\"][3][1] > globals()[f\"h{j}\"][1] > globals()[f\"g{i}\"][0][1]):\n",
    "                globals()[\"g{}\".format(i)].append(globals()[\"h{}\".format(j)])\n",
    "\n",
    "        ga.append(globals()[\"g{}\".format(i)])\n",
    "\n",
    "    for i in ga:\n",
    "        if len(i) == 5:\n",
    "            da.append(i)\n",
    "\n",
    "    # da=(1,2,3,4) # 개체수 없는 시나리오\n",
    "\n",
    "    if len(da) <= 5:\n",
    "        p = 1\n",
    "        print('피더 작동')\n",
    "\n",
    "    else: \n",
    "        for v in da:\n",
    "            if min_gl > v[0][0]:\n",
    "                    min_gl = v[0][0] \n",
    "\n",
    "        min_gl = g1[0][0] # 가장 가까운게 뇌두가 없어서 임시로 값 지정해둔거        \n",
    "\n",
    "        for i,value in enumerate(da):\n",
    "            if min_gl == value[0][0]:\n",
    "                globals()[\"g{}\".format(i)] = np.array(globals()[\"g{}\".format(i)])\n",
    "                best = globals()[\"g{}\".format(i)]\n",
    "                alt = abs(globals()[\"g{}\".format(i)][0]-globals()[\"g{}\".format(i)][-1])\n",
    "                art = abs(globals()[\"g{}\".format(i)][1]-globals()[\"g{}\".format(i)][-1])\n",
    "                alb = abs(globals()[\"g{}\".format(i)][2]-globals()[\"g{}\".format(i)][-1])\n",
    "                arb = abs(globals()[\"g{}\".format(i)][3]-globals()[\"g{}\".format(i)][-1])\n",
    "                altu, artu = int(math.sqrt((alt[0]**2)+(alt[1]**2))), int(math.sqrt((art[0]**2)+(art[1]**2)))\n",
    "                albu, arbu = int(math.sqrt((alb[0]**2)+(alb[1]**2))), int(math.sqrt((arb[0]**2)+(arb[1]**2)))\n",
    "                bgc = {'LT':altu, 'RT':artu, 'LB':albu, 'RB':arbu}\n",
    "                bgc_sorted=sorted(bgc.items(), key=lambda x:x[1])\n",
    "                if bgc_sorted[1][1] - bgc_sorted[0][1] < 13:\n",
    "                    if bgc_sorted[0][0] == 'RT' and bgc_sorted[1][0] == 'RB':\n",
    "                        print(\"0도\")\n",
    "                    elif bgc_sorted[1][0] == 'RT' and bgc_sorted[0][0] == 'RB':\n",
    "                        print(\"0도\")\n",
    "                    elif bgc_sorted[0][0] == 'LT'and bgc_sorted[1][0] == 'RT': \n",
    "                        print(\"90도\")\n",
    "                    elif bgc_sorted[1][0] == 'LT'and bgc_sorted[0][0] == 'RT':\n",
    "                        print(\"90도\")\n",
    "                    elif bgc_sorted[0][0] == 'LT' and bgc_sorted[1][0] == 'LB':\n",
    "                        print(\"180도\")\n",
    "                    elif bgc_sorted[1][0] == 'LT' and bgc_sorted[0][0] == 'LB':\n",
    "                        print(\"180도\")\n",
    "                    elif bgc_sorted[0][0] == 'LB' and bgc_sorted[1][0] == 'RB': \n",
    "                        print(\"270도\")\n",
    "                    elif bgc_sorted[1][0] == 'LB' and bgc_sorted[0][0] == 'RB':\n",
    "                        print(\"270도\")\n",
    "                else:\n",
    "                    if bgc_sorted[0][0] == 'RT':\n",
    "                        print(\"45도\")\n",
    "                    elif bgc_sorted[0][0] == 'LT':\n",
    "                        print(\"135도\")\n",
    "                    elif bgc_sorted[0][0] == 'LB': \n",
    "                        print(\"225도\")\n",
    "                    elif bgc_sorted[0][0] == 'RB':\n",
    "                        print(\"315도\")\n",
    "                print(f'뇌두 좌표 : {globals()[\"g{}\".format(i)][-1]}')\n",
    "\n",
    "        frame_img = cv2.imread(frame_img_path, cv2.IMREAD_COLOR)\n",
    "        frame_img = cv2.cvtColor(frame_img, cv2.COLOR_BGR2RGB)\n",
    "        frame_img = cv2.rectangle(frame_img, (best[0][0], best[0][1]), (best[3][0], best[3][1]),(0,255,0), 3)\n",
    "        frame_img = cv2.circle(frame_img, (best[-1][0],best[-1][1]),5,(255,0,0), -1)\n",
    "        cv2.imshow(\"test\", frame_img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect3: \u001b[0mweights=['C:/Users/AI/Auto_Farming/yolov5/runs/train/insam_yolov5s_results/weights/best.pt'], source=C:/Users\\AI/Auto_Farming/image/masked.png, data=yolov5\\data\\coco128.yaml, imgsz=[480, 480], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5\\runs\\detect, name=exp, exist_ok=True, line_thickness=3, hide_labels=True, hide_conf=True, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  v6.2-219-ga83d2a5 Python-3.9.12 torch-1.12.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/1 C:\\Users\\AI\\Auto_Farming\\image\\masked.png: 480x480 4 Ginsengs, 2 heads, 116.7ms\n",
      "Speed: 1.0ms pre-process, 116.7ms inference, 9.5ms NMS per image at shape (1, 3, 480, 480)\n",
      "Results saved to \u001b[1myolov5\\runs\\detect\\exp\u001b[0m\n",
      "1 labels saved to yolov5\\runs\\detect\\exp\\labels\n"
     ]
    }
   ],
   "source": [
    "for i in rs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPkoUZ+ip0NSrI67SZBVvxy",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
